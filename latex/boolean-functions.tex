\section{Boolean Functions}
\par This section will establish the definition of a {\em Boolean function} and introduce
a few different tools used to measure properties of these functions. First, the
finite field with two elements, denoted $\gftwo$, is defined. The definitions and
notations will follow those found in \cite{bk:cs09}.

% Definition of the finited field GF(2)
\par The two element field $(\gftwo,\oplus,\cdot)$ is the set $\{0,1\}$ with defined binary
operations $\oplus$ and $\cdot$, also commonly referred to as the {\em XOR} and
{\em AND} operators, respectively.
\begin{table}[h!]\label{table:GF(2)}
	\centering
	\begin{tabular}{|c|c|}
		\hline
		XOR&AND\\
		\hline
		$0\oplus0:=0$&$0\cdot0:=0$\\
		$0\oplus1:=1$&$0\cdot1:=0$\\
		$1\oplus0:=1$&$1\cdot0:=0$\\
		$1\oplus1:=0$&$1\cdot1:=1$\\
		\hline
	\end{tabular}
	\caption{Binary Operations for $\gftwo$}
\end{table}
\par It should be clear that $(\gftwo,\oplus,\cdot)$ is a commutative ring with an
identity. Additionally, the only non-zero element $1$ is it's own inverse. Therefore
$(\gftwo,\oplus,\cdot)$ is a finite field. The $n$-dimensional vector space over $\gftwo$
will be denoted by $\gftwo^n$, with the usual inner product. Components of these vectors,
the individual 1s and 0s, will be known as {\em bits}. For two vectors $x,y\in\gftwo^n$
where $x=(x_0,\cdots,x_{n-1})$ and $y=(y_0,\cdots,y_{n-1})$, the scalar product in
$\gftwo^n$ will be defined as $x\cdot y\equiv x_0\cdot y_0 \oplus \cdots \oplus x_{n-1}\cdot y_{n-1}$.

\begin{example}
	Let $a,b\in\gftwo^3$ such that $a=(1,0,1)$ and $b=(0,1,1)$ then
	\begin{align*}
		a+b      &=(1\oplus0,0\oplus1,1\oplus1)=(1,1,0) \\
		a\cdot b &=1\cdot0\oplus0\cdot1\oplus1\cdot1=1
	\end{align*}
\end{example}

\par Each vector in $\gftwo^n$ can be uniquely represented by an integer between
$0$ and $2^{n-1}$. The binary representation function $B$ is one-to-one.
\begin{equation}
	B:\gftwo^n\rightarrow\nnn\cup\{0\}\ {\rm such\ that }\ B(u)\equiv \sum_{i=0}^{n-1}u_i\cdot2^i.
\end{equation}

\par This definition of $B$ has created the convention where the {\em low bit} or
{\em least significant bit} appears on the left and the {\em high bit} or {\em most significant bit}
appears on the right. There is another notable function which counts the number of 1s in each
vector.

\begin{definition}
\label{def:Hamming}
	Let $u,v\in\gftwo^n$. Then $wt:\gftwo^n\rightarrow\nnn\cup\{0\}$ is defined by
	\[
	  wt(u):=\sum_{i=0}^{n-1}u_i
	\]
	and $d:\gftwo^n\times\gftwo^n\rightarrow\nnn\cup\{0\}$ is defined by
	\[
	  d(u,v):=w(u+v).
	\]
	Then $wt(u)$ is the {\em Hamming\ weight} of $u$ and $d(u,v)$ is the
	{\em Hamming\ distance} between $u$ and $v$.
\end{definition}

\begin{remark}
	The Hamming weight of a vector $u\in\gftwo^n$ is the number of 1s in the vector, and the
	Hamming distance between two vectors $u,v\in\gftwo^n$ is the number of bit differences
	between the two vectors.
\end{remark}

\begin{example}
	Let $a,b,c\in\gftwo^5$ such that
	\[
	a=(0,1,1,0,1),\ b=(1,1,1,0,0),\ {\rm and}\ c=(0,0,1,1,0)
	\]
	Then,
	\begin{align*}
		wt(a)=3 &\hspace{5mm} d(a,b)=2\\
		wt(b)=3 &\hspace{5mm} d(a,c)=3\\
		wt(c)=2 &\hspace{5mm} d(b,c)=3.\\
	\end{align*}
\end{example}
	
\par Consider the sequence $(v_0,v_1,\cdots,v_{2^n-1})$ where $B(v_i)=i$. This sequences
is said to be in {\em lexicographical order}.

\par Using the convention of lexicographical ordering and the inner product in $\gftwo^n$, a
matrix can be written which captures all of the possible inner products of two vectors in
$\gftwo^n$. This is a matrix where $u_i\cdot v_j$ appears in the $i$th row and $j$th column.
This particular matrix turns out to be a {\em Hadamard matrix} which will be studied later.

\par To complete this brief discussion about the vectors in $\gftwo^n$ is the
{\em orthogonality principle} that every non-zero vector in $\gftwo^n$ is orthogonal to
exactly half of the vectors in the vectorspace.

\begin{theorem}
	\label{thm:orthogonality-principle}
	Let $u\in\gftwo^n$. Then
	\begin{align}
		\sum_{v\in\gftwo^n}(-1)^{u\cdot v} &= 2^n {\rm \ for\ } u=0 \\
		                                   &= 0 {\rm \ otherwise.}
  \end{align}
\end{theorem}

\begin{proof}
	Let $u=0\in\gftwo^n$. Then $\forall v\in\gftwo^n u\cdot v=0$, so
	$(-1)^{u\cdot v}=1$. Therefore $\sum_{v\in\gftwo^n}(-1)^{u\cdot v}=\lvert\gftwo^n\rvert=2^n$. \\

	Let $u\in\gftwo^n$ where $u\not=0$. Assume the $i$th bit of $u$ is non-zero and
	define $e_i\in\gftwo^n$ as a vector with all zero bits except for the $i$th bit which is $1$. Then
	\begin{align*}
		\sum_{v\in\gftwo^n}(-1)^{u\cdot v} &= \sum_{v\in\gftwo^n}(-1)^{u\cdot (v+e_i)} \\
		                                   &= \sum_{v\in\gftwo^n}(-1)^{u\cdot v}(-1)^{u\cdot e_i} \\
																			 &= -\sum_{v\in\gftwo^n}(-1)^{u\cdot v}.
  \end{align*}
	Therefore, $\sum_{v\in\gftwo^n}(-1)^{u\cdot v}=-\sum_{v\in\gftwo^n}(-1)^{u\cdot v}$, which implies
	$\sum_{v\in\gftwo^n}(-1)^{u\cdot v}=0$.
\end{proof}

\par When introduced to a new vector field, it is natural to begin looking at functions in
that field. The particular function of interest here will be what is known as a {\em Boolean function}.

% Definition of a Boolean Function
\begin{definition}
\label{def:boolean-function}
  Any function $f$ defined such that 
  \begin{equation}
    f:\gftwo^n\rightarrow\gftwo
  \end{equation}
  is a {\em boolean function}.\\
	\\
	The set of all Boolean function on $n$ variables will be denoted by $\mathcal{BF}_n$
\end{definition}

\par Boolean functions have been studied extensively, and there are various properties that
are used to characterize them. Before

\par Oftentimes the codomain of a boolean function represents values of true
and false. The number of boolean functions increases
extremely rapidly as the number of variables increases.

\begin{equation}
  \lvert\{\mathcal{BF}:\fff_2^n\rightarrow\fff_2\}\rvert = 2^{2^n}
\end{equation}

\par As observed by Carlet, consider the set of all boolean functions on 7 variables,
and say that one nanosecond is spent at each function to identify the function and
note some properties about it. If we visited every boolean function this way, it
would take 100 billions times the age of the universe to complete the search.
For eight variables, there are more boolean functions than there are atoms in the
universe.

\par As always, it is best to view an example. Consider the following boolean function
$f$.
\\
\\
\begin{tabular}{|c|c|c|c|c|}
  \hline
  $x_3$&$x_2$&$x_1$&$x_0$&$f(x_3,x_2,x_1,x_0)$\\
  \hline
  0&0&0&0&0\\
  0&0&0&1&1\\
  0&0&1&0&1\\
  0&0&1&1&0\\
  0&1&0&0&1\\
  0&1&0&1&0\\
  0&1&1&0&1\\
  0&1&1&1&0\\
  1&0&0&0&0\\
  1&0&0&1&0\\
  1&0&1&0&1\\
  1&0&1&1&0\\
  1&1&0&0&0\\
  1&1&0&1&0\\
  1&1&1&0&1\\
  1&1&1&1&1\\
  \hline
\end{tabular}
\\
\\
\par The function $f$ can be written as a sum of many different functions.
In particular, it is convenient to use {\em atomic boolean functions}.

\begin{definition}
  An {\em atomic boolean function} is a boolean function that equals 1 for exactly
  one input.
\end{definition}

Then every boolean function can be written as a sum of $w(f)$ standard boolean
functions. For the above example, we have $f=f_1+f_2+f_4+f_6+f_{10}+f_{14}+f_{15}$.
\\
\\
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}
  \hline
  $x_3$&$x_2$&$x_1$&$x_0$&$f$&$f_1$&$f_2$&$f_4$&$f_6$&$f_{10}$&$f_{14}$&$f_{15}$\\
  \hline
  0&0&0&0&0&0&0&0&0&0&0&0\\
  0&0&0&1&1&1&0&0&0&0&0&0\\
  0&0&1&0&1&0&1&0&0&0&0&0\\
  0&0&1&1&0&0&0&0&0&0&0&0\\
  0&1&0&0&1&0&0&1&0&0&0&0\\
  0&1&0&1&0&0&0&0&0&0&0&0\\
  0&1&1&0&1&0&0&0&1&0&0&0\\
  0&1&1&1&0&0&0&0&0&0&0&0\\
  1&0&0&0&0&0&0&0&0&0&0&0\\
  1&0&0&1&0&0&0&0&0&0&0&0\\
  1&0&1&0&1&0&0&0&0&1&0&0\\
  1&0&1&1&0&0&0&0&0&0&0&0\\
  1&1&0&0&0&0&0&0&0&0&0&0\\
  1&1&0&1&0&0&0&0&0&0&0&0\\
  1&1&1&0&1&0&0&0&0&0&1&0\\
  1&1&1&1&1&0&0&0&0&0&0&1\\
  \hline
\end{tabular}
\\
\\
\par This makes it easy to construct the original function $f$ because
the standard boolean functions are well-known.

\begin{align*}
  f_1   &=(1\oplus x_3)(1\oplus x_2)(1\oplus x_1)x_0\\
        &=x_0 \oplus x_1x_0 \oplus x_2x_0 \oplus x_2x_1x_0 \oplus x_3x_0 \oplus x_3x_1x_0
        \oplus x_3x_2x_0 \oplus x_3x_2x_1x_0\\
  f_2   &=(1\oplus x_3)(1\oplus x_2)x_1(1\oplus x_0)\\
  f_4   &=(1\oplus x_3)x_2(1\oplus x_1)(1\oplus x_0)\\
  f_6   &=(1\oplus x_3)x_2x_1(1\oplus x_0)\\
  f_{10}&=x_3(1\oplus x_2)x_1(1\oplus x_0)\\
  f_{14}&=x_3x_2x_1(1\oplus x_0)\\
  f_{15}&=x_3x_2x_1x_0\\
\end{align*}

\par Rather than continuing the computation and finding the polynomial for the boolean function
$f$, an algorithm will be introduced for computing the polynomial coefficients for any boolean
function.

\begin{theorem}
  For a boolean function $f$ of the form $f(x)=\bigoplus_{I\in\mathcal{P}(N)}a_Ix^I$, 
  \begin{equation}
    \forall I \in \mathcal{P}(N) \ \ a_I=\bigoplus_{supp(y)\subseteq I}f(y)
  \end{equation}
\end{theorem}


